{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA2yyNwjUAg3O4oH3ixAEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taruchit/Agentic-AI/blob/main/Agent_with_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fjADXdUg6hAo"
      },
      "outputs": [],
      "source": [
        "!!pip install litellm\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"Lists all files in the current directory.\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"Reads the content of a file.\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the file to read.\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Summary message to return to the user.\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\n",
        "Important!!! Every response MUST have an action.\n",
        "You must ALWAYS respond in this format:\n",
        "\n",
        "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVBcvT8lRTnY",
        "outputId": "dddc9eda-4f5e-4dd4-e16a-e173d20e7905"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? Tell me what files are in the directory.\n",
            "Agent thinking...\n",
            "Agent response: <First, I will list all the files in the current directory to see what contents are available.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'Resume_Taruchit.pdf', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: <The files present in the directory are a configuration folder, a PDF named 'Resume_Taruchit.pdf', and a folder named 'sample_data'. Since there is no specific task given with these files, I will end the interaction by summarizing this information.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"The directory contains a PDF file named 'Resume_Taruchit.pdf' and a folder named 'sample_data'.\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "The directory contains a PDF file named 'Resume_Taruchit.pdf' and a folder named 'sample_data'.\n"
          ]
        }
      ]
    }
  ]
}